import typer
import subprocess
import asyncio
import json
import sys
import yaml
from pathlib import Path
from rich.console import Console
from rich.prompt import Prompt, Confirm
from warden.analysis.application.project_structure_analyzer import ProjectStructureAnalyzer
from warden.cli.commands.install import install as run_install
from warden.cli.commands.init_helpers import (
    configure_llm,
    configure_vector_db,
    select_ci_provider,
    configure_ci_workflow,
    generate_ai_tool_files,
    configure_agent_tools,
)


console = Console()


def _generate_ignore_file(root: Path, meta):
    """Generate .wardenignore based on project type."""
    ignore_path = root / ".wardenignore"
    if ignore_path.exists():
        console.print("[dim].wardenignore exists, skipping.[/dim]")
        return

    content = [
        "# Warden Ignore File",
        "# Auto-generated by Smart Init",
        "",
        "# Version Control",
        ".git/",
        ".svn/",
        "",
        "# Warden",
        ".warden/reports/",
        ".warden/memory/",
        ".warden/embeddings/",
        "",
        "# Dependencies",
        "node_modules/",
        "venv/",
        ".venv/",
        "env/",
        "target/", # Rust
        "vendor/", # Go/PHP
        "dist/",
        "build/",
        "",
        "# IDEs",
        ".idea/",
        ".vscode/",
        "",
        "# Logs",
        "*.log",
        "",
        "# Language Specific"
    ]
    
    if meta.language == "python":
        content.extend(["__pycache__/", "*.pyc", "*.pyo", ".pytest_cache/", ".mypy_cache/", "htmlcov/"])
    elif meta.language in ["javascript", "typescript"]:
        content.extend([".next/", ".nuxt/", "coverage/", ".turbo/"])
    
    with open(ignore_path, "w") as f:
        f.write("\n".join(content))
    console.print("[green]Created .wardenignore (Smart Defaults)[/green]")

def _setup_semantic_search(config_path: Path):
    """
    Initialize semantic search:
    1. Check availability / Auto-install dependencies
    2. Index codebase
    Handles failures gracefully (Soft Failure).
    """
    console.print("\n[bold cyan]üìö Initializing Semantic Index...[/bold cyan]")
    try:
         # Load config
         with open(config_path) as f:
             final_config = yaml.safe_load(f)
             
         ss_config = final_config.get('semantic_search', {})
         if not ss_config.get('enabled'):
             return

         from warden.shared.services.semantic_search_service import SemanticSearchService
         
         # Reset singleton
         SemanticSearchService._instance = None
         service = SemanticSearchService(ss_config)
         
         # Inner function to perform indexing to avoid DRY violation
         async def run_indexing_if_files_exist_async():
             code_extensions = {'.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.go', '.rs', '.cpp', '.c', '.h'}
             files = [f for f in Path.cwd().rglob("*") if f.is_file() and f.suffix in code_extensions and "node_modules" not in str(f) and ".venv" not in str(f) and ".git" not in str(f)]
             
             if not files:
                 console.print("[yellow]No code files found to index.[/yellow]")
                 return

             try:
                 with console.status(f"[bold green]Indexing {len(files)} files... (Ctrl+C to skip)[/bold green]"):
                    await service.index_project(Path.cwd(), files)
                 console.print(f"[green]‚úì Semantic Index Ready ({len(files)} files)[/green]")
             except KeyboardInterrupt:
                 console.print("\n[yellow]‚ö†Ô∏è  Indexing skipped by user.[/yellow]")
                 console.print("[dim]Run 'warden index' later to complete setup.[/dim]")

             if service.is_available():
                 asyncio.run(run_indexing_if_files_exist_async())
             else:
                  console.print("[yellow]Semantic service dependencies missing.[/yellow]")

             if service.is_available():
                 asyncio.run(run_indexing_if_files_exist_async())
             else:
                  console.print("[yellow]Semantic service dependencies missing.[/yellow]")
                  
                  # Use DependencyManager for robust installation
                  from warden.services.dependencies import DependencyManager
                  dep_manager = DependencyManager()
                  
                  required_pkgs = ["chromadb", "sentence-transformers"]
                  success = asyncio.run(dep_manager.install_packages_async(required_pkgs))
                  
                  if success:
                      console.print("[green]Dependencies installed successfully. Retrying setup...[/green]")
                      # Re-instantiate service to pick up new modules
                      service = SemanticSearchService(ss_config)
                      if service.is_available():
                          asyncio.run(run_indexing_if_files_exist_async())
                      else:
                          console.print("[red]Service unavailable even after install.[/red]")
                  else:
                      console.print("[red]Semantic features will be disabled.[/red]")

    except Exception as e:
        console.print("\n[red]‚ùå Semantic Indexing Failed[/red]")
        console.print(f"[red]Error: {str(e)}[/red]")
        console.print("[yellow]üí° Suggestion: Run 'warden index' manually to see detailed errors.[/yellow]")
        console.print("[dim]The project is initialized, but AI features (Orphan/Purpose) may be limited until fixed.[/dim]")

async def _create_baseline_async(root: Path, config_path: Path):
    """Run initial scan and save as baseline."""
    console.print("\n[bold blue]üìâ Creating Baseline...[/bold blue]")
    console.print("[dim]Running initial scan to identify existing technical debt...[/dim]")
    
    try:
        from warden.cli_bridge.bridge import WardenBridge
        bridge = WardenBridge(project_root=root, config_path=str(config_path))
        
        # Run scan on current directory
        # We assume '.' finds all files via scan logic
        # Since execute_pipeline takes a file/dir path, we pass root string.
        result = await bridge.execute_pipeline_async(str(root))
        
        # Save baseline
        baseline_path = root / ".warden" / "baseline.json"
        
        # Extract issues (findings) from result
        # Result structure depends on bridge output. Usually {'success': ..., 'results': ...}
        # We simply save the whole result or a subset as baseline.
        # For now, save entire result.
        
        with open(baseline_path, "w") as f:
            json.dump(result, f, indent=2)
            
        issue_count = result.get("summary", {}).get("total_issues", 0)
        console.print(f"[green]Baseline created with {issue_count} existing issues.[/green]")
        console.print("[dim]Future scans will prioritize NEW issues.[/dim]")
        
    except Exception as e:
        console.print(f"[red]Failed to create baseline: {e}[/red]")

def init_command(
    ctx: typer.Context,
    force: bool = typer.Option(False, "--force", "-f", help="Force initialization even if config exists"),
    mode: str = typer.Option("normal", "--mode", "-m", help="Initialization mode (vibe, normal, strict)"),
    ci: bool = typer.Option(False, "--ci", help="Generate GitHub Actions CI workflow"),
    agent: bool = typer.Option(False, "--agent", help="Configure for AI Agents (Cursor/Claude)"),
) -> None:
    """
    Initialize Warden in the current directory with Smart Detection.
    """
    console.print("[bold blue]üõ°Ô∏è  Initializing Warden (Smart Mode)...[/bold blue]")

    warden_dir = Path(".warden")
    warden_dir.mkdir(parents=True, exist_ok=True)
    
    # --- Step 1: Detect Project ---
    console.print("[bold blue]üîç Detecting project environment...[/bold blue]")
    
    # Use Core Analyzer
    analyzer = ProjectStructureAnalyzer(Path.cwd())
    # Run async analysis synchronously
    context = asyncio.run(analyzer.analyze_async())
    
    # Map ProjectContext to metadata expected by init
    # We create a simple object to hold the data compatible with previous logic
    class MetaAdapter:
        pass
    meta = MetaAdapter()
    meta.language = context.primary_language
    meta.frameworks = [context.framework.value] if context.framework.value != "none" else []
    meta.project_type = context.project_type.value
    meta.ci_providers = [] # Core analyzer detects this but stores in config_files/special_dirs differently?
    # PSA stores build tools in context.build_tools
    meta.build_tools = [bt.value for bt in context.build_tools]
    
    # Suggest frames logic (Dynamic Discovery)
    # 1. Base Core Frames (built-in frames that come with warden-core)
    # Available built-in frames: security, resilience, orphan, fuzz, property, spec, gitchanges
    meta.suggested_frames = ["security", "resilience", "orphan"]
    
    # 2. Dynamic Language-Specific Frames (Registry Search)
    try:
        from warden.services.package_manager.registry import RegistryClient
        registry = RegistryClient()  # Use default paths
        
        # Sync if cache is missing (first run)
        if not registry._catalog_cache:
            console.print("[dim]Syncing registry for suggestions...[/dim]")
            asyncio.run(registry.sync_async())
            
        # Get languages to check (fall back to primary if detected is empty)
        languages_to_check = context.detected_languages or [context.primary_language]
        
        # Collect suggestions from all languages
        found_frames = 0
        all_suggestions = set()
        
        for lang in set(languages_to_check):
            if not lang or lang == "unknown":
                continue
                
            suggestions = registry.suggest_for_language(lang)
            if suggestions:
                for s in suggestions:
                    all_suggestions.add(s)
        
        if all_suggestions:
            meta.suggested_frames.extend(list(all_suggestions))
            console.print(f"[dim]Found {len(all_suggestions)} language-specific frames for {', '.join(set(languages_to_check))}[/dim]")

    except Exception as e:
        console.print(f"[dim yellow]Warning: frame suggestion failed: {e}[/dim yellow]")

    if meta.project_type in ["api", "backend", "microservice"]:
        # Add fuzz and property testing for API/backend projects
        if "fuzz" not in meta.suggested_frames:
            meta.suggested_frames.append("fuzz")
        if "property" not in meta.suggested_frames:
            meta.suggested_frames.append("property")
    # Helper to check for CI config files from context.config_files
    ci_files = {".github/workflows": "github-actions", ".gitlab-ci.yml": "gitlab-ci", "Jenkinsfile": "jenkins"}
    for f, p in ci_files.items():
        if f in context.config_files:
            meta.ci_providers.append(p)

    console.print(f"   [green]‚úì[/green] Language: [cyan]{meta.language}[/cyan]")
    console.print(f"   [green]‚úì[/green] Framework: [cyan]{', '.join(meta.frameworks) if meta.frameworks else 'None detected'}[/cyan]")
    console.print(f"   [green]‚úì[/green] Type: [cyan]{meta.project_type}[/cyan]")
    
    # Language Distribution Table
    from rich.table import Table
    if context.language_breakdown:
        console.print()
        table = Table(title="Detected Languages", box=None)
        table.add_column("Language", style="cyan")
        table.add_column("Distribution", justify="right", style="magenta")
        table.add_column("Status", style="dim")
        
        from warden.shared.languages.registry import LanguageRegistry
        from warden.ast.domain.enums import CodeLanguage
        
        sorted_stats = sorted(context.language_breakdown.items(), key=lambda x: x[1], reverse=True)
        for lang_id, percent in sorted_stats:
            is_included = lang_id in context.detected_languages
            status = "[green]‚óè[/green] Included" if is_included else "[dim]‚óã Ignored (<2%)[/dim]"
            
            # Get pretty name from registry
            try:
                lang_enum = CodeLanguage(lang_id)
                defn = LanguageRegistry.get_definition(lang_enum)
                pretty_name = defn.name if defn else lang_id.capitalize()
            except ValueError:
                pretty_name = lang_id.capitalize()

            table.add_row(
                pretty_name, 
                f"{percent:.1f}%", 
                status
            )
        console.print(table)
        console.print()

    console.print(f"Suggested Frames: {', '.join(meta.suggested_frames)}")
    # The original code had an `except` block here, but with ProjectStructureAnalyzer,
    # we assume it either succeeds or raises an error that should propagate if not handled.
    # For now, we'll remove the try/except around detection as the new analyzer is more robust.
    # If specific errors need handling, they should be added here.

    # --- Step 2: Mode Selection ---
    console.print("\n[bold cyan]üéöÔ∏è  Select Operation Mode[/bold cyan]")
    console.print("1. [bold green]Vibe Mode[/bold green] (Silent, Critical Only) - Best for active dev")
    console.print("2. [bold yellow]Normal Mode[/bold yellow] (High+Critical) - Standard PR checks")
    console.print("3. [bold red]Strict Mode[/bold red] (All Issues) - Zero tolerance / Security audit")
    
    mode_choice = Prompt.ask("Select Mode", choices=["1", "2", "3"], default="2")
    
    mode_config = {}
    if mode_choice == "1": # Vibe
        mode_config = {"fail_fast": False, "min_severity": "critical", "quiet": True}
        meta.suggested_frames = [f for f in meta.suggested_frames if f in ["security", "env-security"]] # Vibe uses minimal frames
    elif mode_choice == "3": # Strict
        mode_config = {"fail_fast": True, "min_severity": "low", "strict": True}
    else: # Normal
        mode_config = {"fail_fast": False, "min_severity": "high"}

    # Load existing config for defaults
    existing_config = {}
    config_path = warden_dir / "config.yaml"
    if config_path.exists():

        try:
            with open(config_path) as f:
                existing_config = yaml.safe_load(f) or {}
        except: pass

    # --- Step 3: LLM Config ---
    llm_config, new_env_vars = configure_llm(existing_config)
    provider = llm_config["provider"]
    model = llm_config["model"]

    # Update .env
    env_path = Path(".env")
    if new_env_vars:
        mode = "a" if env_path.exists() else "w"
        current_env = env_path.read_text() if env_path.exists() else ""
        with open(env_path, mode) as f:
            if mode == "a": f.write("\n")
            for k, v in new_env_vars.items():
                if k not in current_env:
                    f.write(f"{k}={v}\n")
        console.print("[green]Updated .env[/green]")

        # Create .env.example
        env_example_path = Path(".env.example")
        if not env_example_path.exists():
            with open(env_example_path, "w") as f:
                f.write("# Warden Environment Variables\n")
                if provider == "azure":
                    f.write("AZURE_OPENAI_API_KEY=\n")
                    f.write("AZURE_OPENAI_ENDPOINT=\n")
                    f.write("AZURE_OPENAI_DEPLOYMENT_NAME=\n")
                elif provider != "none" and provider != "ollama":
                    # Generic key
                    f.write(f"{provider.upper()}_API_KEY=\n")
            console.print("[green]Created .env.example[/green]")

    # --- Step 4: Vector Database ---
    vector_config = configure_vector_db()


    # --- Step 4: Generate Config ---
    if not config_path.exists():

        
        # Build frames_config based on detection
        frames_config = {}
        for frame in meta.suggested_frames:
            frames_config[frame] = {"enabled": True}
        
        # Apply mode settings
        if mode_choice == "1": # Vibe
            for f in frames_config:
                 frames_config[f]["severity_threshold"] = "critical"
        
        config_data = {
            "version": "1.0.0",
            "project": {
                "name": Path.cwd().name,
                "language": meta.language,
                "type": meta.project_type,
                "frameworks": meta.frameworks
            },
            "dependencies": {
                "architectural": "latest",
                "security": "latest"
            },
            "llm": {
                "provider": provider,
                "model": model,
                "smart_model": model,
                "fast_model": llm_config.get("fast_model", "qwen2.5-coder:0.5b"),
                "timeout": 300
            },
            "frames": meta.suggested_frames,
            "frames_config": frames_config,
            "settings": {
                "fail_fast": mode_config["fail_fast"],
                "enable_classification": True,
                "mode": ["vibe", "normal", "strict"][int(mode_choice)-1],
                "use_llm": provider != "none",
                "use_local_llm": llm_config.get("use_local_llm", False)
            },
            "semantic_search": vector_config
        }
        # Preserve Azure details if selected
        if provider == "azure":
            config_data['llm']['azure'] = {
                "endpoint": "${AZURE_OPENAI_ENDPOINT}",
                "api_key": "${AZURE_OPENAI_API_KEY}",
                "deployment_name": "${AZURE_OPENAI_DEPLOYMENT_NAME}",
                "api_version": "2024-02-15-preview"
            }
        
        # New root manifest (Standardized to .warden/config.yaml)
        root_config_path = warden_dir / "config.yaml"
        with open(root_config_path, "w") as f:
            yaml.dump(config_data, f, default_flow_style=False)
        console.print(f"[green]Created project configuration: [bold]{root_config_path}[/bold][/green]")
        
        config_path = root_config_path 

    else:
        # Config exists - Offer Update/Merge
        console.print(f"[yellow]Config file exists: {config_path}[/yellow]")
        if Confirm.ask("Update configuration with detected settings? (Merges frames & mode)", default=False):

            
            # Update Frames - merge new suggestion into existing
            existing_frames = set(existing_config.get('frames', []))
            new_frames = set(meta.suggested_frames)
            merged_frames = list(existing_frames.union(new_frames))
            existing_config['frames'] = merged_frames
            
            # Update Frames Config - enable new frames
            if 'frames_config' not in existing_config:
                existing_config['frames_config'] = {}
            
            for frame in meta.suggested_frames:
                if frame not in existing_config['frames_config']:
                    existing_config['frames_config'][frame] = {"enabled": True}
                    if mode_choice == "1":
                        existing_config['frames_config'][frame]["severity_threshold"] = "critical"
            
            # Update Project Metadata
            existing_config['project']['language'] = meta.language
            existing_config['project']['type'] = meta.project_type
            existing_config['project']['frameworks'] = meta.frameworks
            
            # Update Settings based on Mode
            if 'settings' not in existing_config: existing_config['settings'] = {}
            existing_config['settings']['fail_fast'] = mode_config["fail_fast"]
            existing_config['settings']['mode'] = ["vibe", "normal", "strict"][int(mode_choice)-1]
            if "min_severity" in mode_config:
                 existing_config['settings']['min_severity'] = mode_config["min_severity"]
                 
            # Ensure Semantic Search is present
            existing_config["semantic_search"] = vector_config
            
            # Save
            with open(config_path, "w") as f:
                yaml.dump(existing_config, f, default_flow_style=False)
            console.print("[green]Merged configuration successfully.[/green]")


    # --- Step 5: Ignore Files ---
    _generate_ignore_file(Path.cwd(), meta)

    # Create .warden/ignore.yaml from template
    ignore_yaml_path = warden_dir / "ignore.yaml"
    if not ignore_yaml_path.exists():
        try:
            import importlib.resources
            ignore_template = importlib.resources.read_text("warden.templates", "ignore.yaml")
            with open(ignore_yaml_path, "w") as f:
                f.write(ignore_template)
            console.print(f"[green]Created ignore configuration: {ignore_yaml_path}[/green]")
        except Exception as e:
            console.print(f"[yellow]Warning: Could not create ignore.yaml: {e}[/yellow]")

    # --- Step 6: Example Rules ---
    rules_dir = warden_dir / "rules"
    rules_dir.mkdir(exist_ok=True)
    example_rule_path = rules_dir / "my_custom_rules.yaml"
    if not example_rule_path.exists():
        example_content = """# Example Custom Rule Definition
# Check https://github.com/warden-ai/docs for full syntax

rules:
  - id: "company-no-print"
    description: "Do not use print statements in production code"
    severity: "warning"
    patterns:
      - "print("
    exclude:
      - "tests/**"
      - "scripts/**"
"""
        with open(example_rule_path, "w") as f:
            f.write(example_content)
        console.print(f"[green]Created example rules: {example_rule_path}[/green]")

    # --- Step 7: Update Config with Comments ---
    # We re-read the just created/merged config to append comments if needed
    # Or ensures generation includes it.
    
    # If we created a new config in Step 4, we likely used yaml.dump.
    # yaml.dump removes comments. We need to append the example usage at the end manually
    # or handle it better.
    
    # Let's read the file as text and check if the comment exists, if not, append it.
    if config_path.exists():
        current_content = config_path.read_text()
        comment_block = """
# --- Custom Rules Configuration ---
# To enable your custom rules, uncomment the following lines:
#
custom_rules:
  - .warden/rules/my_custom_rules.yaml
"""
        if "custom_rules:" not in current_content:
            with open(config_path, "a") as f:
                f.write(comment_block)
            console.print("[green]Added custom rules configuration[/green]")

        # Semantic Search is now AUTO-ADDED, so no hint needed.
        
        # HINT: CI Output Formats
        if "ci:" not in current_content and "output:" not in current_content:
            ci_hint = """
# --- CI/CD Output Configuration ---
# Generate reports in multiple formats (Markdown, JSON, SARIF)
#
# ci:
#   enabled: true
#   output:
#     - format: markdown
#       path: .warden/reports/warden-report.md
#     - format: sarif
#       path: .warden/reports/warden-report.sarif
"""
            with open(config_path, "a") as f:
                f.write(ci_hint)

        console.print("[green]Added configuration examples (Rules, Semantic Search, CI)[/green]")

    # --- Step 8: Semantic Indexing ---
    _setup_semantic_search(config_path)

    # --- Step 9: Agent Configuration (New) ---
    if agent or Confirm.ask("\nConfigure for AI Agents (Cursor/Claude)?", default=True):
        try:
            # Generate AI tool files from templates
            generate_ai_tool_files(Path.cwd(), llm_config)
            # Configure MCP and hooks
            configure_agent_tools(Path.cwd())
        except Exception as e:
            console.print(f"[red]Failed to configure agent tools: {e}[/red]")

    # --- Step 9: Baseline ---
    if Confirm.ask("\nCreate Baseline from current issues? (Recommended for existing projects)", default=True):
        try:
             asyncio.run(_create_baseline_async(Path.cwd(), config_path))
        except KeyboardInterrupt:
             console.print("\n[yellow]‚ö†Ô∏è  Baseline creation skipped by user.[/yellow]")
        except Exception as e:
             console.print(f"[red]Warning: Failed to create baseline: {e}[/red]")

    # --- Step 9: CI/CD (Template-Based) ---
    if ci or Confirm.ask("\nGenerate CI/CD Workflow?", default=False):
        # Use detected branch or default
        branch = "main"
        try:
            branch = subprocess.check_output(["git", "branch", "--show-current"], text=True).strip()
        except Exception:
            pass

        # Select CI provider
        ci_provider = select_ci_provider()

        # Generate workflow from template
        if configure_ci_workflow(ci_provider, llm_config, Path.cwd(), branch):
            console.print("[green]‚úì CI/CD workflow configured successfully![/green]")

    # --- Step 10: Verify Built-in Frames ---
    console.print("\n[bold blue]üì¶ Verifying Built-in Frames...[/bold blue]")
    try:
        from warden.validation.infrastructure.frame_registry import FrameRegistry
        registry = FrameRegistry()
        frames = registry.discover_all(project_root=Path.cwd())
        frame_names = [f().name for f in frames]
        console.print(f"[green]‚úì Found {len(frames)} built-in frames: {', '.join(frame_names[:5])}{'...' if len(frames) > 5 else ''}[/green]")
    except Exception as e:
        console.print(f"[yellow]Warning: Could not verify frames: {e}[/yellow]")

    # Optional: Try to install additional frames from Hub (non-blocking)
    if Confirm.ask("\nInstall additional frames from Warden Hub? (requires network)", default=False):
        try:
            from warden.cli.commands.update import update_command
            try:
                update_command()
            except Exception:
                console.print("[yellow]Warning: Could not update registry.[/yellow]")

            run_install(frame_id=None)
        except Exception as e:
            console.print(f"[yellow]Warning: Hub install failed: {e}[/yellow]")
            console.print("[dim]Built-in frames are still available.[/dim]")

    console.print("\n[bold green]‚ú® Warden Initialization Complete![/bold green]")
    console.print("Run [bold cyan]warden scan[/bold cyan] to start.")
    console.print("[dim]Available frames: security, resilience, orphan, fuzz, property[/dim]")
