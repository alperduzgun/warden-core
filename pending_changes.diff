diff --git a/src/warden/cli/commands/scan.py b/src/warden/cli/commands/scan.py
index feb5f5f..aaa81c8 100644
--- a/src/warden/cli/commands/scan.py
+++ b/src/warden/cli/commands/scan.py
@@ -5,7 +5,6 @@ from typing import Dict, List, Optional
 from datetime import datetime
 from rich.console import Console
 from rich.table import Table
-from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
 
 # Internal imports
 from warden.cli_bridge.bridge import WardenBridge
@@ -316,23 +315,12 @@ async def _run_scan_async(
 
     final_result_data = None
 
-    progress = Progress(
-        SpinnerColumn(),
-        TextColumn("[bold blue]{task.description}"),
-        BarColumn(bar_width=40),
-        "[progress.percentage]{task.percentage:>3.0f}%",
-        "‚Ä¢",
-        TextColumn("[dim]{task.fields[status]}"),
-        TimeElapsedColumn(),
-        console=console,
-        transient=True
-    )
-
-    overall_task = None
-    current_phase_task = None
+    processed_units = 0
+    total_units = 0
+    current_phase = "Initializing..."
 
     try:
-        with progress:
+        with console.status(f"[bold blue]üõ°Ô∏è  Scanning...[/bold blue]", spinner="dots") as status:
             # Execute pipeline with streaming
             async for event in bridge.execute_pipeline_stream_async(
                 file_path=paths,
@@ -347,48 +335,72 @@ async def _run_scan_async(
                     evt = event['event']
                     data = event.get('data', {})
 
-                    if evt == "progress_init":
-                        overall_task = progress.add_task("Overall Progress", total=data['total_units'], status="Initializing...")
+                    if verbose:
+                        console.print(f"[dim]Progress Event: {evt} - {data}[/dim]")
+
+                    if evt == "discovery_complete":
+                        total_units = data.get('total_files', 0)
+                        status.update(f"[bold blue]üõ°Ô∏è  Scanning...[/bold blue] [dim]Discovered {total_units} files[/dim] (0/{total_units})")
                     
-                    elif evt == "progress_update" and overall_task is not None:
+                    elif evt == "pipeline_started":
+                        # Use file_count as baseline if total_units not yet initialized
+                        if total_units <= 0:
+                            total_units = data.get('file_count', 0)
+                        status.update(f"[bold blue]üõ°Ô∏è  Scanning...[/bold blue] [dim]Starting pipeline...[/dim] (0/{total_units})")
+
+                    elif evt == "progress_init":
+                        new_total = data.get('total_units', 0)
+                        if new_total > 0:
+                            total_units = new_total
+                        status.update(f"[bold blue]üõ°Ô∏è  Scanning...[/bold blue] [dim]{current_phase}[/dim] ({processed_units}/{total_units})")
+                    
+                    elif evt == "progress_update":
                         increment = data.get('increment', 0)
-                        status = data.get('status', data.get('phase', 'Processing...'))
-                        progress.update(overall_task, advance=increment, status=status)
+                        processed_units += increment
                         
-                        # Handle dynamic unit addition (e.g. Analysis/Verification finding counts)
-                        if "total_units" in data:
-                            # Safe task retrieval to avoid IndexError
-                            task = next((t for t in progress.tasks if t.id == overall_task), None)
-                            if task:
-                                progress.update(overall_task, total=task.total + data['total_units'])
+                        # If frame_id is present but no increment, count it as 1 to be safe
+                        if increment == 0 and "frame_id" in data:
+                             processed_units += 1
 
-                    if format == "text":
-                        if evt == "phase_started":
-                            phase_name = data.get('phase')
-                            if not verbose:
-                                if current_phase_task is not None:
-                                    progress.remove_task(current_phase_task)
-                                current_phase_task = progress.add_task(f"Phase: {phase_name}", total=None, status="In Progress")
-                            else:
-                                console.print(f"[bold blue]‚ñ∂ Phase:[/bold blue] {phase_name}")
+                        if "total_units" in data:
+                            # Only update total if it's explicitly provided and larger
+                            new_total = data['total_units']
+                            if new_total > total_units:
+                                total_units = new_total
                         
-                        elif evt == "frame_completed":
-                            stats["total"] += 1
-                            name = data.get('frame_name', data.get('frame_id'))
-                            status = data.get('status', 'unknown')
-                            icon = "‚úÖ" if status == "passed" else "‚ùå" if status == "failed" else "‚ö†Ô∏è" 
-                            style = "green" if status == "passed" else "red" if status == "failed" else "yellow"
-                            findings_count = data.get('findings', data.get('issues_found', 0))
-
-                            if status == "passed":
-                                stats["passed"] += 1
-                            elif status == "failed":
-                                stats["failed"] += 1
-                            else:
-                                stats["skipped"] += 1
-                                
-                            if verbose:
-                                console.print(f"  {icon} [{style}]{name}[/{style}] ({data.get('duration', 0):.2f}s) - {findings_count} issues")
+                        # Update current phase/status
+                        new_status = data.get('status', data.get('phase'))
+                        if new_status:
+                            current_phase = new_status
+                        
+                        # Update the sticky status line
+                        status.update(f"[bold blue]üõ°Ô∏è  Scanning...[/bold blue] [dim]{current_phase}[/dim] ({processed_units}/{total_units})")
+                    
+                    elif evt == "phase_started":
+                        current_phase = data.get('phase', current_phase)
+                        status.update(f"[bold blue]üõ°Ô∏è  Scanning...[/bold blue] [dim]{current_phase}[/dim] ({processed_units}/{total_units})")
+                        if verbose:
+                            console.print(f"[bold blue]‚ñ∂ Phase:[/bold blue] {current_phase}")
+
+                    elif evt == "frame_completed":
+                        # Fallback: if we didn't get a progress_update for this frame, increment here
+                        # But be careful not to double count. Most frames send progress_update.
+                        stats["total"] += 1
+                        name = data.get('frame_name', data.get('frame_id'))
+                        frame_status = data.get('status', 'unknown')
+                        icon = "‚úÖ" if frame_status == "passed" else "‚ùå" if frame_status == "failed" else "‚ö†Ô∏è" 
+                        style = "green" if frame_status == "passed" else "red" if frame_status == "failed" else "yellow"
+                        findings_count = data.get('findings', data.get('issues_found', 0))
+
+                        if frame_status == "passed":
+                            stats["passed"] += 1
+                        elif frame_status == "failed":
+                            stats["failed"] += 1
+                        else:
+                            stats["skipped"] += 1
+                            
+                        if verbose:
+                            console.print(f"  {icon} [{style}]{name}[/{style}] ({data.get('duration', 0):.2f}s) - {findings_count} issues")
 
                 elif event_type == "result":
                     # Final results
diff --git a/src/warden/pipeline/application/orchestrator/frame_executor.py b/src/warden/pipeline/application/orchestrator/frame_executor.py
index 6781a05..ff85a1a 100644
--- a/src/warden/pipeline/application/orchestrator/frame_executor.py
+++ b/src/warden/pipeline/application/orchestrator/frame_executor.py
@@ -551,10 +551,30 @@ class FrameExecutor:
                      f_results = []
                 else:
                     try:
-                        f_results = await asyncio.wait_for(
-                            frame.execute_batch_async(files_to_scan),
-                            timeout=getattr(self.config, 'frame_timeout', 300.0)
-                        )
+                        # Revert to per-file execution if batch is not explicitly handled or for better granularity
+                        # Note: Most frames use batching for performance, but we need to report per-file for UX
+                        f_results = []
+                        total_files_to_scan = len(files_to_scan)
+                        
+                        # If frame handles batch natively and efficiently, we call it in smaller chunks
+                        # to maintain both performance and progress visibility
+                        CHUNK_SIZE = 5 # Small chunk for better responsiveness
+                        
+                        for i in range(0, total_files_to_scan, CHUNK_SIZE):
+                            chunk = files_to_scan[i:i+CHUNK_SIZE]
+                            chunk_results = await asyncio.wait_for(
+                                frame.execute_batch_async(chunk),
+                                timeout=getattr(self.config, 'frame_timeout', 300.0)
+                            )
+                            if chunk_results:
+                                f_results.extend(chunk_results)
+                                # Update progress per group
+                                if self.progress_callback:
+                                    self.progress_callback("progress_update", {
+                                        "increment": len(chunk_results),
+                                        "frame_id": frame.frame_id,
+                                        "phase": f"Validating {frame.name}"
+                                    })
                         
                         if f_results:
                             files_scanned = len(f_results)
@@ -570,13 +590,6 @@ class FrameExecutor:
                             for res in f_results:
                                 if res and res.findings:
                                     frame_findings.extend(res.findings)
-                            
-                            # Update progress for scanned batch
-                            if self.progress_callback:
-                                self.progress_callback("progress_update", {
-                                    "increment": files_scanned,
-                                    "frame_id": frame.frame_id
-                                })
                                     
                     except asyncio.TimeoutError:
                         logger.warning("frame_batch_execution_timeout", frame=frame.frame_id)
diff --git a/src/warden/pipeline/application/orchestrator/orchestrator.py b/src/warden/pipeline/application/orchestrator/orchestrator.py
index 1fb05bb..a588163 100644
--- a/src/warden/pipeline/application/orchestrator/orchestrator.py
+++ b/src/warden/pipeline/application/orchestrator/orchestrator.py
@@ -551,7 +551,7 @@ class PhaseOrchestrator:
                 for finding in frame_res.get('findings', []):
                     # Robust identification: rule_id + file (relative to root)
                     rid = finding.get('rule_id') if isinstance(finding, dict) else getattr(finding, 'rule_id', None)
-                    fpath = finding.get('file_path') if isinstance(finding, dict) else getattr(finding, 'path', finding.get('path'))
+                    fpath = finding.get('file_path') if isinstance(finding, dict) else getattr(finding, 'path', getattr(finding, 'file_path', None))
                     
                     if not fpath: continue
                     
@@ -652,9 +652,7 @@ class PhaseOrchestrator:
             else:
                 val = getattr(f, 'severity', None)
             
-            
-            
-            return str(val).lower() if val else ''
+            return str(val).lower() if val else 'medium' # Default to medium if missing
 
         # Helper to get review_required from finding
         def is_review_required(f: Any) -> bool:
diff --git a/src/warden/pipeline/domain/pipeline_context.py b/src/warden/pipeline/domain/pipeline_context.py
index 6e2c73a..574eaa5 100644
--- a/src/warden/pipeline/domain/pipeline_context.py
+++ b/src/warden/pipeline/domain/pipeline_context.py
@@ -329,15 +329,20 @@ class PipelineContext:
 
         # Add issues context
         if self.findings:
+            # Helper for safe access
+            def _get_sev(f):
+                if isinstance(f, dict): return f.get('severity', 'unknown')
+                return getattr(f, 'severity', 'unknown')
+
             if concise:
                 # Just counts for concise mode
-                crit = sum(1 for f in self.findings if str(f.get('severity')).lower() == 'critical')
+                crit = sum(1 for f in self.findings if str(_get_sev(f)).lower() == 'critical')
                 total = len(self.findings)
                 context_parts.append(f"ISSUES: {total} ({crit} critical)")
             else:
                 severity_counts = {}
                 for finding in self.findings:
-                    sev = finding.get("severity", "unknown")
+                    sev = _get_sev(finding)
                     severity_counts[sev] = severity_counts.get(sev, 0) + 1
                 context_parts.append(f"ISSUES FOUND: {severity_counts}")
 
