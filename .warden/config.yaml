project:
  name: warden-core
  description: Warden configuration for warden-core
  language: python
  sdk_version: '3.11'
  framework: fastapi
  project_type: monorepo
  detected_at: '2025-12-24T16:35:53.922859'
llm:
  provider: azure_openai
  model: gpt-4o
  azure:
    endpoint: ${AZURE_OPENAI_ENDPOINT}
    api_key: ${AZURE_OPENAI_API_KEY}
    deployment_name: ${AZURE_OPENAI_DEPLOYMENT_NAME}
    api_version: ${AZURE_OPENAI_API_VERSION}
  fallback:
    provider: groq
    api_key: ${GROQ_API_KEY}
  timeout: 300
  max_retries: 2
frames:
- security
- chaos
- orphan
- architectural
- stress
- env-security
- demo-security
- property
- fuzz
frames_config:
  orphan:
    enabled: true
    use_llm_filter: true
    ignore_test_files: true
    ignore_private: false
    ignore_imports:
    - annotations
    - TYPE_CHECKING
  security:
    enabled: true
    priority: critical
    is_blocker: false
    checks:
    - sql_injection
    - xss
    - hardcoded_secrets
    - command_injection
    - path_traversal
  chaos:
    enabled: true
    priority: high
    checks:
    - timeout_handling
    - retry_logic
    - circuit_breaker
    - error_recovery
  architectural:
    enabled: true
    priority: low
  stress:
    enabled: true
    checks:
    - api_load_testing
    - async_performance
  env-security:
    enabled: true
  demo-security:
    enabled: true
    check_hardcoded_passwords: true
    severity_level: high
ci:
  enabled: true
  fail_on_blocker: true
  output:
  - format: markdown
    path: ./WARDEN_REPORT.md
  - format: json
    path: ./warden-report.json
settings:
  fail_fast: false
  timeout: 300
  frame_timeout: 120
  enable_pre_analysis: true
  enable_analysis: true
  enable_classification: true
  enable_validation: true
  enable_fortification: true
  enable_cleaning: true
  pre_analysis_config:
    use_llm: true
    llm_threshold: 0.7
    batch_size: 10
    cache_enabled: true
advanced:
  max_workers: 4
  frame_timeout: 300
  debug: false
