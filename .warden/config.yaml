project:
  name: warden-core
  description: Warden configuration for warden-core
  language: python
  sdk_version: '3.11'
  framework: fastapi
  project_type: monorepo
  detected_at: '2025-12-24T16:35:53.922859'
llm:
  provider: azure_openai
  model: gpt-4o
  azure:
    endpoint: ${AZURE_OPENAI_ENDPOINT}
    api_key: ${AZURE_OPENAI_API_KEY}
    deployment_name: ${AZURE_OPENAI_DEPLOYMENT_NAME}
    api_version: ${AZURE_OPENAI_API_VERSION}
  fallback:
    provider: groq
    api_key: ${GROQ_API_KEY}
  timeout: 300
  max_retries: 2
frames:
- security
- chaos
- orphan
- architectural
- stress
- env-security      # Custom frame (auto-discovered from ~/.warden/frames/)
- demo-security     # Demo custom frame
frames_config:
  orphan:
    enabled: true    # Enabled olarak değiştirdim
    use_llm_filter: true
    ignore_test_files: true
    ignore_private: false
    ignore_imports:
    - annotations
    - TYPE_CHECKING
  security:
    enabled: true
    priority: critical
    is_blocker: false  # Blocker'ı false yaptım ki diğer frame'ler de çalışsın
    checks:
    - sql_injection
    - xss
    - hardcoded_secrets
    - command_injection
    - path_traversal
  chaos:
    enabled: true
    priority: high
    checks:
    - timeout_handling
    - retry_logic
    - circuit_breaker
    - error_recovery
  architectural:
    enabled: true    # Enabled olarak değiştirdim
    priority: low
  stress:
    enabled: true
    checks:
    - api_load_testing
    - async_performance
  env-security:
    enabled: true
    # Config auto-generated from frame.yaml!
    # Override only what you need:
    # check_hardcoded_credentials: false
    # severity_level: high
  demo-security:
    enabled: true
    # Demo frame with auto-config
    check_hardcoded_passwords: true
    severity_level: high
ci:
  enabled: true
  fail_on_blocker: true
  output:
  - format: markdown
    path: ./WARDEN_REPORT.md
  - format: json
    path: ./warden-report.json
settings:
  fail_fast: false  # Tüm frame'lerin çalışması için false yaptım
  timeout: 300
  frame_timeout: 120
  enable_pre_analysis: true  # Enable PRE-ANALYSIS phase for context detection
  enable_analysis: true  # Enable ANALYSIS phase for quality metrics
  enable_classification: true  # Enable CLASSIFICATION phase for frame selection
  enable_validation: true  # Enable VALIDATION phase (frames)
  enable_fortification: true  # Enable FORTIFICATION phase for security fixes
  enable_cleaning: true  # Enable CLEANING phase for code improvements
  pre_analysis_config:
    use_llm: true  # ✅ Enable LLM for better analysis
    llm_threshold: 0.7  # Use LLM when confidence < threshold
    batch_size: 10  # Files to analyze per LLM call
    cache_enabled: true  # Cache LLM responses for similar patterns
advanced:
  max_workers: 4
  frame_timeout: 300
  debug: false
